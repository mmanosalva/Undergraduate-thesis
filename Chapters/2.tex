%!TEX root = ../main.tex

\thispagestyle{empty}
\vspace{-0.7cm}

\cleanchapterquote{Hasta el día de hoy, los matemáticos han intentado en vano descubrir algún orden en la secuencia de números primos, y tenemos razones para creer que es un misterio al que la mente humana nunca penetrará}{Leonhard Euler}{}

Para comenzar con este capítulo presentaremos el teorema fundamental de la aritmética (TFA), una pieza crucial en cualquier trabajo sobre teoría de números.\\


\begin{theorem}[TFA]
Todo entero $n>1$ se puede escribir como producto de primos de manera única salvo el orden de los factores, es decir:

$$n=\prod_{j=1}^{m}p_j^{k_j}$$
\end{theorem}

Escribiremos $p^m\mid\mid n$ siempre que si $p^m\mid n$ entonces $p^{m+1}\nmid n$, es decir, $p^m$ es la potencia exacta que divide a $n$, esto nos permite escribir el TFA como:

$$n= \prod_{p^m\mid\mid n}p^m$$

\section{Funciones aritmética}

\begin{definition}
Una función aritmética es una función con dominio los naturales y rango $\R$ o $\C$, es decir $a$ es función aritmética si:

$$f:\N \to \mathbb{F}$$

con $\mathbb{F}=\C$ o $\mathbb{F}=\R$
\end{definition}

Esta definición nos muestra que las funciones aritmética no son más que sucesiones de números reales o complejos, en algunos casos será útil considerarlas de esta  manera y de manera análoga a  las sucesiones las denotaremos como $a_n$, donde cada $a_n$ representa $f(n)$. Veamos algunos ejemplos importantes:

\begin{itemize}
\item[$\bullet$] \textbf{Función constante k:}

$$k(n)=k, \text{ para todo } n \in \N $$

\item[$\bullet$] \textbf{Función unidad:}

$$e(n)=\begin{cases}
1 \quad n=1\\
0 \quad n\neq 1.
\end{cases}$$

\item[$\bullet$] \textbf{Función número de divisores:} $\tau(n)$, el número de divisores positivos de $n$ (incluyendo 1 y n)

$$\tau(n)=\sum_{j\mid n}1$$

\item[$\bullet$] \textbf{Función suma de divisores:} $\sigma(n)$, la suma de los divisores positivos de $n$

$$\sigma(n)=\sum_{j\mid n}j$$

\item[$\bullet$] \textbf{Función de Möbius:} $\mu(n)$, se define como

$$\mu(n)=\begin{cases}
1  &n=1\\
0  &\text{si n no es libre de cuadrados}\\
(-1)^k &\text{si n tiene k factores primos.}
\end{cases}$$

\item[$\bullet$] \textbf{Función phi de Euler:} $\varphi(n)$, el número de enteros positivos $m\leq n$ que son primos relativos a n ($(m,n)=1$)

$$\varphi(n)=\sum_{\substack{m=1 \\(m, n)=1}}^n 1$$

\item[$\bullet$]\textbf{Función de Von Mangoldt:} $\Lambda(n)$, se define como

$$\Lambda(n)= \begin{cases}\log p & n=p^m \\ 0 & \text { en otro caso }\end{cases}$$

\item[$\bullet$]\textbf{Función identidad:} $N(n)$, la función identidad se define como:

$$N(n)=n$$ 

\end{itemize}

Por la naturaleza de $\N$, existen dos clases importantes de funciones aritmética, las funciones aditivas y multiplicativas:

\begin{itemize}

\item[$\bullet$] Las funciones aditivas que satisfacen
$$
f(m n)=f(m)+f(n) \quad \text { siempre que }(m, n)=1,
$$


\item[$\bullet$] las funciones multiplicativas que satisfacen
$$
f(m n)=f(m) f(n) \text { siempre que }(m, n)=1 .
$$


\end{itemize}


Si una función aditiva o multiplicativa satisface la  propiedad para cualquier par de números naturales $m$ y $n$, se dirá que la función es completamente aditiva o completamente multiplicativa, respectivamente, las funciones aditivas y multiplicativas están determinadas por sus valores en las potencias de los números primos.\\ 

\begin{proof}
Supongamos que $f$ es aditiva y $n>1$, por el TFA:

$$f(n)=f\left(\prod_{p^m\mid\mid n}p^m\right)=\sum_{p^m\mid \mid n} f(p^{m})$$

Ahora, si $f$ es multiplicativa:

$$f(n)=f\left(\prod_{p^m\mid\mid n}p^m\right)=\prod_{p^m\mid\mid n}f(p^m) $$
\end{proof}

Si además la función es completamente multiplicativa:

$$f(n)=f\left(\prod_{i=1}^{m}p_i^{k_i}\right)=\prod_{i=1}^{m} f(p_i)^{k_i} $$

Lo que también ocurre para funciones completamente aditivas, cambiando el producto por una suma.  Una propiedad adicional que será útil para caracterizar estas funciones es que si $f$ es aditiva y no identicamente nula, entonces para algún $n$, $f(1\cdot  n)=f(1)+f(n)$, así $f(1)=0$, análogamente si $f$ es multiplicativa y no identicamente nula $f(1\cdot n)=f(1)f(n)$, $f(1)=1$.\\

Ahora veamos que aunque la función de Von Mangoldt, parece extraña, su definición es natural y nos permite obtener una versión logarítmica del teorema fundamental de la aritmética.

\begin{theorem}
Dado $n\in \N$, $n>1$ entonces:

$$\log(n)=\sum_{j\mid n}\Lambda(j)$$
\end{theorem}

\begin{proof}

Note que si $n>1$, entonces por el TFA:

$$\log(n)=k_1\log(p_1)+\ldots+k_m\log(p_m)$$

 Los $p_j$ de la igualdad son los primos de su descomposición y $k_j$ sus potencias respectivas. Así, esta igualdad nos dice que en el cálculo de $\log(n)$ solo importan los valores del $\log$ en los divisores primos o potencias de primos, luego:

 $$\log(n)=\sum_{j\mid n}\Lambda(j)$$
\end{proof}

Sin embargo, la principal motivación para introducir la función de Von Mangoldt es que sus sumas parciales $\displaystyle\sum_{n \leq x} \Lambda(n)$ son la suma ponderada de las potencias primos $p^m \leq x$, tomando como peso $\log p$, el peso correcto para compensar la densidad de primos. No es difícil demostrar que las potencias $p^m$ con $(m \geq 2)$ contribuyen poco en la suma anterior.\\

De hecho, estudiar el comportamiento asintótico de la suma anterior resultará equivalente a estudiar el de la función de contadora de primos $\pi(x)$; de hecho, el TNP es equivalente a la afirmación

$$
\lim _{x \rightarrow \infty} \frac{1}{x} \sum_{n \leq x} \Lambda(n)=1 .
$$

Esta equivalencia nos dará el camino a la prueba del teorema de los números primos, lo que la convierte en una función aritmética muy importante.\cite{hildebrand2006introduction}

\begin{definition}

Las funciones $\psi(x)$ y $\vartheta(x)$ de Chevyshev se definen como sigue:

$$\vartheta(x)=\sum_{p\leq x}\log p, \quad \quad \psi(x)=\sum_{n \leq x} \Lambda(n)$$

\end{definition}

\subsection{La función de Möbius}

Es natural preguntarse por la definición de la función de Möbius, ya que de todas parece ser la más extraña, uno se preguntaría si hay una forma de motivarla... En efecto:\\

Consideremos la función: 

$$L(x)=\sum_{n\leq x}\log(n)$$

Note que aplicando el teorema anterior:

\begin{equation}
L(x)=\sum_{n\leq x}\log(n)=\sum_{n\leq x}\sum_{j\mid n}\Lambda(j)
\end{equation}

Ahora vamos a aplicar una técnica muy útil y frecuente en teoría de números, el cambio de orden de sumación, para esto vamos a cambiar $n$ y $d$ de orden en la doble suma (1.1) y conservaremos la condición $j\mid n$.

\begin{align*}
    L(x)&=\sum_{n\leq x}\log(n)=\sum_{n\leq x}\sum_{j\mid n}\Lambda(j)\\
    &=\sum_{j \leq x} \sum_{\substack{n \leq x \\
j \mid n}} \Lambda(j)\\
&=\sum_{j \leq x} \Lambda(j) \sum_{\substack{n \leq x \\
j \mid n}} 1
.\end{align*}

Ahora, ¿cuántos enteros positivos $n\leq x$ hay tal que $j\mid n$?, pues exactamente $\dfrac{x}{j}$, así:

\begin{align*}
    L(x)&=\sum_{j\leq x}\Lambda(j)\sum_{m\leq \frac{x}{j}}1\\
\end{align*}

Y cambiando nuevamente el orden de sumación:

\begin{align*}
    L(x)&=\sum_{m\leq x}\sum_{j\leq \frac{x}{m}}\Lambda(j)\\
    &=\sum_{m\leq x}\psi\left(\frac{x}{m}\right)
\end{align*}

Esta identidad la abordaremos más adelante, pero de momento sabemos que podemos escribir a $L(x)$ en términos de $\psi(x)$, ¿y si queremos lo opuesto?, ie. a $\psi(x)$ en términos de  $L(x)$, ¿podemos \textbf{invertir} el papel de las funciones?. Vamos a abordar esta pregunta poniéndola en un contexto más general.\\

Siguiendo a \cite{levinson1969motivated}, supongamos $F(x)$ y $G(x)$ funciones aritmética con $G(x)=\displaystyle\sum_{n\leq x}F\left(\dfrac{x}{n}\right)$, tenemos que:

$$G \left( \frac{x}{2} \right)=F \left( \dfrac{x}{2} \right)+F \left( \frac{x}{4} \right)+F \left( \frac{x}{6} \right)+\ldots$$

Así:

$$G(x)-G \left( \frac{x}{2} \right)=F(x)+F \left( \dfrac{x}{3} \right)+F \left( \dfrac{x}{5} \right)+\ldots$$

Podemos pensar que continuar restando los términos $G \left( \dfrac{x}{j} \right)$ nos permitirá obtener la inversión, sin embargo el término $G \left( \dfrac{x}{3} \right)$ contiene a $F \left( \dfrac{x}{6} \right)$, por tanto:

$$
G(x)-G\left(\frac{x}{2}\right)-G\left(\frac{x}{3}\right)=F(x)+F\left(\frac{x}{5}\right)-F\left(\frac{x}{6}\right)+F\left(\frac{x}{7}\right)+\ldots
$$
Así, en los siguientes pasos debemos eliminar $-F\left(\dfrac{x}{6}\right)$. Esto se lograría sumando $G\left(\dfrac{\mathrm{x}}{6}\right)$ y no restándolo. La suma anterior nos muestra además que no necesitamos restar 

$G\left(\dfrac{x}{4}\right)$ pues $F\left(\dfrac{x}{4}\right)$ ya desapareció al restar $G\left(\dfrac{x}{2}\right)$.\\


Así, podemos intuir que necesitamos multiplicar $G(\frac{x}{j})$ en cada sumando, por una función que nos de el signo adecuado (sume y reste, según se necesite) o anule el término, como ocurre en el caso de $G\left(\frac{x}{4}\right)$. Denotemos esta función que estamos buscando como $\mu(x)$. Si suponemos que existe dicha función, entonces:

\begin{equation}
F(x)=\sum_{j \leqslant x} \mu(j) G\left(\frac{x}{j}\right)
\end{equation}

Además de ello, ya tenemos algunos valores de $\mu$, $\mu(1)=1$, $\mu(2)=\mu(3)=-1, \mu(4)=0$ y $\mu(6)=1$. Podemos de momento darnos cuenta que estos valores parecen coincidir con los que obtendríamos al evaluar la función de Möbius, lo cual no es ninguna coincidencia, sin embargo aún no podemos afirmar que son en esencia la misma función. Note que por la definición de $G$:

\begin{equation}
G\left(\frac{\mathrm{x}}{\mathrm{j}}\right)=\sum_{k\leq \frac{x}{j}} F\left(\frac{x}{j \mathrm{k}}\right)
\end{equation}

Por tanto al reemplazar (1.3) en (1.2), obtenemos:

\begin{align*}
    F(x)&=\sum_{j \leqslant x} \mu(j)\sum_{jk\leq x} F\left(\frac{x}{j \mathrm{k}}\right)=\sum_{jk\leq x}\mu(j)F \left( \frac{x}{jk} \right)\\
    &=\sum_{n\leq x}F \left( \frac{x}{n} \right)\sum_{jk=n}\mu(j)
.\end{align*}

Finalmente:

\begin{equation}
F(x)=F(x)+\sum_{1<n\leq x}F \left( \frac{x}{n} \right)\sum_{jk=n}\mu(j)
\end{equation}

Para obtener la inversión necesitamos que la doble suma en (1.4) se anule, y dado que no tenemos condiciones sobre $F$, la función $\mu$ debe cumplir que si $n \neq 1$

$$\sum_{j\mid n}\mu(j)=0$$

En efecto, \textit{la función que cumple esta propiedad es... la función de Möbius}.

\begin{theorem}
Sea $n \geqslant 1$, entonces:

$$\sum_{\mathrm{d} \mid \mathfrak{n}} \mu(\mathrm{d})=e(n)$$

\end{theorem}
Antes de continuar con la prueba de este resultado notemos que la suma en (1.2) en realidad no recorre los $j\leqslant x$, sino los $j$ que son divisores de $x$ ya que $G$ es función aritmética y por tanto $\frac{x}{j}$ es necesariamente un número natural. Así:

\begin{equation}
F(x)=\sum_{j \mid x} \mu(j) G\left(\frac{x}{j}\right)
\end{equation}

Esta suma sobre los divisores de $n$ llevará el nombre de convolución o producto de Dirichlet y nos permitirá darle al conjunto de las funciones aritmética una estructura de Monoide Abeliano, estas ideas sin embargo las estudiaremos en la  siguiente sección. Ahora continuemos con la prueba.\\

\begin{proof}

Si $n=1$, entonces $1=e(1)=\mu(1)$, si $n\neq 1$, entonces por el teorema fundamental de la aritmética $n=\displaystyle\prod_{i=1}^k p_i^{\alpha_i}$, note que los únicos divisores $d$ tales que $\mu(d)\neq 0$ son los que toman la forma $d=p_{i_1}\ldots p_{i_j}$ donde $\mathcal{K}=\{i_1,\ldots, i_j\}\subseteq \{1,\ldots,k\}$, en este caso $\mu(d)=(-1)^{|\mathcal{K}|}$. Necesitamos saber cuántas veces va a aparecer este valor en la suma, es decir dado un $0\leq r\leq k$ fijo, ¿cuántos subconjuntos de $\{1,\ldots,k\}$ tienen cardinal $r$?, exactamente $\displaystyle \binom{k}{r}$. Así la suma toma la forma:

\begin{align*}
    \sum_{d\mid n}\mu(d)&=1+\sum_{i}\mu(p_i)+\sum_{i,j}\mu(p_ip_j)+\ldots+\mu(p_1\ldots p_k)\\
    &=1-k+\binom{k}{2}+\ldots+(-1)^k\\
    &=\sum_{r=1}^k\binom{k}{r}(-1)^r=(1-1)^k=0
.\end{align*}

\end{proof}

Aplicando esto a la función $L(x)$, obtenemos que:

$$\psi(x)=\sum_{j\mid n} \mu(j)L \left( \frac{n}{j} \right)$$

La fórmula en (1.5) se conoce como inversión de Möbius, las ideas aquí sin embargo fueron abordadas de manera informal, para poder presentar un argumento riguroso, necesitamos, como se menciono antes, introducir la convolución de Dirichlet, que además nos permitirá obtener propiedades importantes de algunas de las funciones aritmética que hemos presentado en esta sección.

\section{Convolución de Dirichlet}

Siguiendo las ideas de la  sección anterior, presentamos la siguiente definición:
\pagebreak

\begin{definition}
Sean f y g funciones aritméticas. Definimos la convolución o producto de Dirichlet como: 

$$(f*g)(n)=\sum_{\mathrm{d} \mid \mathrm{n}} \mathrm{f}(\mathrm{d}) \mathrm{g}\left(\frac{\mathrm{n}}{\mathrm{d}}\right).$$

O simplemente $f*g$.
\end{definition}

Algunos resultados del capítulo anterior se pueden escribir en términos de convolución, por ejemplo, el TFA se puede presentar como:

$$\log n=\sum_{j\mid n}\Lambda(j)=\Lambda * 1$$

donde 1, denota la función constante 1, también $\psi(x)=\mu*L$, pero la convolución no solo se introduce como una manera de simplificar notación, como mencionamos antes, esta tiene propiedades importantes que nos permitirán darle una estructura algebraica a las funciones aritmética.

\begin{theorem}
Sean $f$ y $g$ funciones aritméticas. Entonces se cumple lo siguiente

\begin{itemize}

\item[$\bullet$] $f * g=g * f$.

\item[$\bullet$] $(f * g) * h=f *(g * h)$.

\item[$\bullet$] $e * f=f * e=f$.

\end{itemize}

\end{theorem}


\begin{proof}

Primero note que $\displaystyle\sum_{j\mid n} f(j)g \left( \frac{n}{j} \right)=\sum_{jk=n} f(j)g(k)$, ya que en ambos casos la suma recorre los divisores de $n$, luego:

$$\begin{aligned}
(f * g)(n) & =\sum_{j_1 j_2=n} f\left(j_1\right) g\left(j_2\right )=\sum_{j_1 j_2=n} g\left(j_1\right) f\left(j_2\right) \\
& =(g * f)(n)
\end{aligned}$$

Ya que no importa el orden en el la suma recorra los divisores, lo que prueba la conmutatividad. Ahora, recordemos que $e(n)=1$ si $n=1$ y 0 si $n\neq 1$, por tanto:
$$(e*f)(n)=(f*e)(n)=\sum_{j\mid n}f(j)e \left( \frac{n}{j} \right)$$

Así, como $e \left( \dfrac{n}{j} \right)=0$ si $j\neq n$, los términos de la suma son cero excepto cuando $j=n$, 

$$(e*f)(n)=(f*e)(n)=\sum_{j\mid n}f(j)e \left( \frac{n}{j} \right)=f(n)=f$$

Para probar la asociatividad, considere $N=g*h$ y $M=f*g$, luego

$$
\begin{aligned}
(f * N)(n) & =\sum_{j \mid n} f(j) N\left(\frac{n}{j}\right) \\
& =\sum_{j_1 j_2=n} f\left(j_1\right) N\left(j_2\right) \\
& =\sum_{j_1 j_2=n} f\left(j_1\right)\left(\sum_{j_3 j_4=j_2} g\left(j_3\right) h\left(j_4\right)\right) \\
& =\sum_{j_1 j_3 j_4=n} f\left(j_1\right) g\left(j_3\right) h\left(j_4\right)\\
& =\sum_{j_1 j_3 j_4=n} f\left(j_3\right) g\left(j_4\right) h\left(j_1\right)\\
& =\sum_{j_1 j_2=n}\left(\sum_{j_3 j_4=j_2} f\left(j_3\right) g\left(j_4\right)\right) h\left(j_1\right)\\
& =\sum_{j_1 j_2=n} M\left(j_2\right) h\left(j_1\right)\\
&=(M * h)(n)
\end{aligned}
$$

\end{proof}

Hemos  probado en particular que la función $e$ es el elemento neutro de la convolución, sabemos además que $\mu *1=e$, es decir la función de Möbius tiene inverso multiplicativo, con estas nuevas herramientas podemos presentar una prueba corta y formal de la fórmula de inversión de Möbius (1.5).

\begin{theorem}[Fórmula de inversión de Möbius]
Sean $f$ y $g$ funciones aritmética, entonces $f=g*1$ si y solo si $g=\mu* f$.
\end{theorem}

\begin{proof}
Note que $f=g*1$ si y solo si $\mu*f=\mu*g*1=g*\mu*1=g*e=g$
\end{proof}

Sin embargo, no toda función aritmética tiene inverso multiplicativo, el caso más evidente es tomar la función constante $N=0$, note que para toda $f$, $f*N=N$. Esto nos lleva a la pregunta: ¿bajo qué condiciones una función aritmética tiene inverso multiplicativo?, la respuesta podría venir de estudiar las características que no permiten que $N$ lo tenga... A saber, $N$ \textit{se anula en todo punto}, ¿bastaría con que esta función no se anule en todo su dominio para que tenga inversa?, o ¿en algún punto en particular?, la respuesta nos viene del siguiente teorema, basta con que la función no se anule en 1 para poder garantizar además la \textit{unicidad}.

\begin{theorem}
 
Sea $f$ una función aritmética tal que $f(1) \neq 0$. Entonces existe una única función aritmética $g$ tal que $f*g=e$.

\end{theorem} 

\begin{proof}
Note que si $n=1$, entonces $f(1)g(1)=e(1)=1$, así $g(1)=\dfrac{1}{f(1)}$, ahora  supongamos que $g$ se ha definido para todos lo valores $1<k<n$, luego como $f*g(n)=0$:

\begin{equation}
0=\sum_{d\mid n}g(d)f \left( \frac{n}{d} \right)=\sum_{\substack{d \mid n \\
d<n}} f\left(\frac{n}{d}\right) g(d)+f(1) g(n)
\end{equation}

Así:

$$g(n) =\frac{-1}{f(1)} \sum_{\substack{d \mid n \\
d<n}} f\left(\frac{n}{d}\right) g(d)$$

Esto nos define $g$ de manera recursiva, lo que concluye el resultado.

\end{proof}


Esto nos permite dotar a estas funciones aritmética de una estructura de grupo Abeliano, ya que si $f(1)\neq 0$ y $g(1)\neq 0$, entonces $f*g(1)=f(1)g(1)\neq 0$.\\


\begin{theorem}
Sean $f$ y $g$ funciones aritméticas multiplicativas, entonces $f * g$ también es multiplicativa.
\end{theorem}

\begin{proof}
Sean $x, y \in \mathbb{N}$ tal que $(x, y)=1$. Note que cada divisor $d \mid xy$ puede escribirse de manera única como $d=mn$ donde $m \mid x$ y $n \mid y$, además $(m, n)=1$ y $\left(\dfrac{x}{m}, \dfrac{y}{n}\right)=1$. Por lo tanto

$$
\begin{aligned}
(f * g)(xy) & =\sum_{d \mid xy} f(d) g\left(\frac{xy}{d}\right) \\
& =\sum_{\substack{m|x \\
n| y}} f(mn) g\left(\frac{xy}{mn}\right) \\
& =\sum_{\substack{m|x \\
n| y}} f(m) g\left(\frac{x}{m}\right) f(n) g\left(\frac{y}{n}\right) \\
& =\sum_{m \mid x} f(m) g\left(\frac{y}{m}\right) \sum_{n \mid y} f(n) g\left(\frac{y}{n}\right) \\
& =(f * g)(x)(f * g)(y) .
\end{aligned}
$$

Así $f * g$ es multiplicativa.
\end{proof}


\begin{theorem}
Si $f$ es multiplicativa, entonces $g=f^{-1}$ también es multiplicativa
\end{theorem}

Donde $f^{-1}$ denota su inversa, presentaremos una prueba siguiendo a \cite{hildebrand2006introduction}\\

\begin{proof}
Queremos ver que:

\begin{equation}
g(n_1n_2)=g(n_1)g(n_2) \quad \text{si} \quad (n_1,n_2)=1.
\end{equation}

Procedamos por inducción matemática. Sea $n=n_1 n_2$, si $n_1 n_2=1$, entonces $n_1=n_2=1$, luego:

$$g(1\cdot 1)=g(1)=\dfrac{1}{f(1)}=1=g(1)g(1)$$

Supongamos ahora que $g$ satisface (1.7) para todo $k_1k_2\geq 2$ tal que $k_1k_2<n$ y sean $n_1$ y $n_2$ tales que $n_1n_2=n$ y $(n_1,n_2)=1$, por (1.6) tenemos que:

$$
\begin{aligned}
0 & =\sum_{d \mid n_1 n_2} f(d) g\left(\frac{n_1n_2}{d}\right) \\
&=\sum_{\substack{d_1 \mid n_1 \\
d_2\mid n_2\\ d_1d_2<n}} f(d_1)f(d_2) g \left( \frac{n_1}{d_1} \right)g \left( \frac{n_2}{d_2} \right)+ g(n_1n_2)\\
&=\sum_{\substack{d_1 \mid n_1 \\
d_2\mid n_2}} f(d_1)f(d_2) g \left( \frac{n_1}{d_1} \right)g \left( \frac{n_2}{d_2} \right)+ g(n_1n_2)-g(n_1)g(n_2)\\
& =(f * g)\left(n_1\right)(f * g)\left(n_2\right)+\left(g\left(n_1 n_2\right)-g\left(n_1\right) g\left(n_2\right)\right)
\end{aligned}
$$

Luego:

$$g\left(n_1\right) g\left(n_2\right)=e\left(n_1\right) e\left(n_2\right)+g\left(n_1 n_2\right)$$

\vspace*{0.2cm}

Y como $n_1n_2\geq 2$, entonces $n_1\geq 2$ o $n_2\geq 2$, así $e(n_1)e(n_2)=0$, por tanto $g(n_1n_2)=g(n_1)g(n_2)$.
\end{proof}

\begin{corollary}
Sea $\mathcal{M}$ el conjunto de funciones aritmética multiplicativas, entonces $(\mathcal{M},*)$ es un grupo Abeliano.
\end{corollary}

\subsection{Propiedades de algunas funciones aritmética}

Finalizaremos esta sección con algunas propiedades importantes de las funciones aritmética que definimos el inicio del capítulo.

\vspace*{-0.5cm}

\subsubsection{La función \texorpdfstring{$\varphi$}{Lg} de Euler}

La propiedad del teorema (1.3) nos permite manipular sumas  con condiciones de coprimalidad, es decir sumas sobre los $n$ que son coprimos con un entero $k$ fijo. Considere el conjunto $C_k=\{n \text{ | } (n,k)=1\}$, note que la función característica del conjunto $C_k$ es:

$$
\mathbbm{1}_{C_k}(n)=\sum_{d \mid(n, k)} \mu(d)=e((n,k)),
$$

Una aplicación de esto, nos permite obtener la siguiente propiedad de la función $\varphi$ de Euler:

$$\begin{aligned}
\varphi(n) & =\sum_{\substack{m \leq n \\
(m, n)=1}} 1=\sum_{m\leq n}\mathbbm{1}_{C_n}(m) \\
& =\sum_{m \leq n} \sum_{d \mid(m, n)} \mu(d) \\
& =\sum_{d \mid n} \mu(d) \sum_{\substack{m \leq n \\
d \mid m}} 1 \\
& =\sum_{d \mid n} \mu(d) \frac{n}{d}\\
&=\mu*N(n)=n \sum_{d \mid n} \frac{\mu(d)}{d} .
\end{aligned}$$

Es claro que la función $N$ es multiplicativa por definición, luego esta propiedad nos permite probar que la función $\varphi$ es multiplicativa, por el teorema (1.7) basta ver que en efecto $\mu$ lo es, algo interesante teniendo en cuenta que esta propiedad en cursos de álgebra se sigue de $\Z_{mn}=\Z_m\times \Z_n$ \text{ si } $(m,n)=1$.



\begin{theorem}
La función $\mu$ es multiplicativa:
\end{theorem}

\begin{proof}

Supongamos que $n=n_1n_2$, si $n=1$, entonces $n_1=n_2=1$, $\mu(n)=\mu(n_1)\mu(n_2)=1$. Ahora supongamos que $\mu(k)=\mu(k_1)\mu(k_2)$, para todo $k=k_1k_2$ tal que $1<k<n$ y $(k_1,k_2)=1$ y sean $n_1,n_2$ tales que $n_1n_2=n$ y $(n_1,n_2)=1$, tenemos que:

\begin{align*}
    0&=\sum_{d\mid n_1n_2}\mu(d)\\
    &=\sum_{\substack{d_1\mid n_1\\ d_2\mid n_2\\d_1d_2<n}}\mu(d_1)\mu(d_2)+\mu(n_1n_2)\\
    &=\sum_{\substack{d_1\mid n_1}}\mu(d_1)\sum_{d_2\mid n_2}\mu(d_2)+\mu(n_1n_2)-\mu(n_1)\mu(n_2)\\
    &=\mu(n_1n_2)-\mu(n_1)\mu(n_2)
.\end{align*}

Así, por el principio de inducción matemática se sigue el resultado.
\end{proof}

\begin{corollary}
La función $\varphi(n)$ tiene las siguientes propiedades:

\begin{itemize}
\item[i)] $\varphi(mn)=\varphi(m)\varphi(n)$ si $(m,n)=1$

\item[ii)] $\varphi(p^n)=p^n-p^{n-1}$

\item[iii)] $\varphi(n)=n\displaystyle\prod_{p\mid n}\left(1-\frac{1}{p}\right)  $
\end{itemize}
\end{corollary}

\begin{proof}

i) Como $\varphi=\mu* N$, se sigue del teorema anterior.\\

ii) Note que si $n=p^k$, entonces:

\begin{align*}
    \varphi(p^k)&=p^k\sum_{j\mid p^k}\frac{\mu(j)}{j}\\
    &=p^k\left(1+\frac{\mu(p)}{p}+\frac{\mu(p^2)}{p^2}+\ldots+\frac{\mu(p^k)}{p^k}\right)\\
    &=p^k \left(1-\frac{1}{p}\right)=p^k-p^{k-1}
.\end{align*}

iii) Sea $n>1$, por el TFA se sigue que:

\begin{align*}
    \varphi(n)&= \varphi \left( \prod_{p^m\mid\mid n}p^m \right)\\
    &= \prod_{p^m\mid\mid n}\varphi(p^m)\\
    &=  \prod_{p^m\mid\mid n} p^m-p^{m-1}\\
    &=n \prod_{p\mid n}\left( 1-\frac{1}{p} \right)
.\end{align*}
\end{proof}

Al inicio del capítulo mencionamos que las funciones aritmética están totalmente determinadas por sus valores en las potencias de primos, esta propiedad nos permite probar de manera sencilla afirmaciones del estilo $f*g=h$, siempre que $f,g$ y $h$ sean funciones multiplicativas, basta ver que $f*g(p^m)=h(p^m)$, veamos un ejemplo:

\begin{theorem}
La función $\varphi(n)$ satisface la propiedad:

$$n=\sum_{j\mid n}\varphi(j)$$
\end{theorem}

\begin{proof}
La afirmación se puede  escribir como $N=\varphi*1$, como estas funciones son multiplicativas, entonces basta ver que la identidad se tiene en las potencias de primos, en efecto:

\begin{align*}
    \sum_{j\mid p^m}\varphi(j)&=\varphi(1)+\varphi(p)+\varphi(p^2)+\varphi(p^3)+\ldots+\varphi(p^m)\\
    &=1+(\slashed{p}-1)+(\slashed{p^2}-\slashed{p})+(\slashed{p^3}-\slashed{p^2})+\slashed{ } \ldots\not{ } +(p^m-\slashed p^{m-1})\\
    &=p^m
.\end{align*}
\end{proof}

Esta identidad  también puede probarse usando propiedades  de la convolución:

\begin{align*}
    \sum_{j\mid n}\varphi(j)=\varphi*1(n)=(N*\mu)*1(n)=N*(\mu*1)(n)=N*e(n)=n
\end{align*}

\subsubsection{Las funciones número y suma de divisores}

También  podemos aplicar la convolución para obtener también propiedades de la funciones suma y número de divisores, por ejemplo:

\begin{equation}
\sigma(n)=\sum_{j\mid n}j=N*1(n) \quad \text{y} \quad \tau(n)=\sum_{j\mid n}1=1*1(n)
\end{equation}

Note que $\sigma*\varphi=(N*1)*(\mu*N)=(N*e)*N=N*N$, en efecto:

$$\sigma*\varphi(n)=N*N(n)=\sum_{j\mid n}j\cdot\frac{n}{j}=n\sum_{j\mid n}1=n\tau(n)$$

Con lo que obtenemos una propiedad  interesante que relaciona estas 3 funciones aritmética, pero  además (1.8) nos dice también que las funciones $\sigma$ y $\tau$ son multiplicativas por ser convolución de funciones multiplicativas. Observemos una última propiedad de estas funciones, que nos permite caracterizar la noción de ser primo.

\begin{prop}
Un entero $n$ es primo si y solo si $\sigma(n)+\varphi(n)=n\tau(n)$
\end{prop}

\begin{proof}

Si $n$ es primo, entonces $\varphi(n)=n-1$, $\sigma(n)=n+1$ y $\tau(n)=2$, luego es claro que $\sigma(n)+\varphi(n)=n\tau(n)$.Veamos ahora que si $n$ no es primo entonces no se sigue el teorema:\\

Si $n$ no es primo entonces $\varphi(n)<n-1$, ahora note que:

$$\sigma(n)=\sum_{j\mid n}j=1+\sum_{\substack{j\mid n\\ j>1}}j\leq 1+n(\tau(n)-1) $$

Luego:

$$\sigma(n)+\varphi(n)<n-1+1+n\tau(n)-n=n\tau(n)$$
\end{proof}

\section{Sumación Parcial}

Los resultados que hemos podido obtener hasta el momento solo se centran en casos finitos, en sumas sobre los divisores de un entero $n$ fijo o sobre los $k$ que son primos relativos a $n$, estos son casos privilegiados, nuestro objetivo sigue siendo el TNP, para esto necesitamos poder obtener relaciones asintóticas, algunas funciones como $\mu$ o $\varphi$ aparentan comportamientos caóticos al graficarlas en función de $n$ y por tanto no tiene mucho sentido estudiar un comportamiento asintótico para  ellas, sin embargo, algunas funciones aritmética $f(n)=a_n$ tienen buen comportamiento en la media, en el sentido de que sus sumas parciales:

$$A(x)=\sum_{n\leq x}a_n$$

Tienden a ser suaves  conforme $x\to \infty$ y frecuentemente podemos estudiarlas de manera precisa, ejemplo de esto son $\pi(x)$ o $\psi(x)$. En esta sección estudiaremos algunos de los métodos principales para obtener dichas estimaciones, estimaciones que nos darán un camino a la prueba del TNP.\\

Sea $f:(a,b) \longrightarrow \mathbb{R}$ una función real, denotamos:
   \begin{align*}
       f(c-)&=\lim_{x \rightarrow c^-} f(x), \hspace{0.1cm} c \in (a,b] \notag \\
       f(c+)&=\lim_{x \rightarrow c^+} f(x), \hspace{0.1cm} c \in [a,b) 
   \end{align*}

\begin{definition}
    Sea $f$ una función real definida en $[a,b]$. Suponga que $f(x+)$ y $f(x-)$ existen para todo $x \in (a,b)$. Definimos: 
       \begin{itemize}
           \item $f(x)-f(x-)$: Salto a izquierda de $f$ en $x$.
           \item $f(x+)-f(x)$: Salto a derecha de $f$ en $x$.
           \item $[f(x)-f(x-)]+[f(x+)-f(x)]=f(x+)-f(x-)$: Salto de $f$ en $x$.
       \end{itemize}
\end{definition}

\subsection{La integral de Riemann-Stieltjes}

Sean $P=\{x_0,x_1,...,x_n\}\in\mathcal{P}[a,b]$ (las particiones del intervalo $[a,b]$) y   $t_{k}\in [x_{k-1},x_k]$ cualesquiera. Una suma de la forma $$S(P,f)=\sum_{k=1}^{n}f(t_k)\Delta x_k$$ Se denomina \textbf{suma de Riemann} de $f$ en $[a,b]$, recordamos que $\Delta x_k=x_k-x_{k-1}$.\\

La integral usual se define como el límite de las sumas de Riemann, esta definición nos da una correspondencia importante: Toda integral de Riemann se puede ver como el límite de una suma, una serie.\\

Sin embargo, no toda suma se puede ver como una integral bajo esta definición, si tenemos una con una condición de sumación sobre, por ejemplo, los números primos, no hay un camino claro para expresarla como una integral, la solución a este problema viene de generalizar la noción de integral.\\

\pagebreak

La propiedad deseada la obtendremos de la integral de Riemann-Stieltjes.

\begin{definition}
\phantom{uwu}
\begin{itemize}

    \item[i)] Sean $P=\{x_0,x_1,...,x_n\}\in\mathcal{P}[a,b]$ (las particiones del intervalo $[a,b]$) y   $t_{k}\in [x_{k-1},x_k]$ cualesquiera. 
    
    Una suma de la forma $$S(P,f,\alpha)=\sum_{k=1}^{n}f(t_k)\Delta \alpha_k$$ se denomina \textbf{suma de Riemann-Stieltjes} de $f$ con respecto a $\alpha$ en $[a,b]$.
    
    \item[ii)] Decimos que $f$ es \textbf{Riemann-Integrable} con respecto a $\alpha$ en $[a,b]$, y escribimos ``$f\in \mathcal{R}(\alpha)$ en $[a,b]$'', si existe $A\in \mathbb R$ que satisface que:\\ 
    para todo $\varepsilon>0$ existe $P_{\varepsilon}\in \mathcal{P}[a,b]$ tal que si para toda $P\supset P_{\varepsilon}$ y para cualquier elección de puntos $t_{k}\in [x_{k-1},x_k]$, entonces $$\mid S(P,f,\alpha) - A\mid <\varepsilon.$$
    \end{itemize}
\end{definition}

Donde $\Delta\alpha_k=\alpha(x_k)-\alpha(x_{k-1})$, cuando $A$ existe, es único y se denota por $$\int_a^b fd\alpha \quad \text{o} \quad \int_{a}^{b} f(x)d\alpha(x).$$ 
La función $f$ es llamada \textit{integrando} y la función $\alpha$ es llamada \textit{integrador}.\\


Note que la integral de Riemann no es más que un caso particular de la de Riemann-Stieltjes, cuando $\alpha(x)=x$.\\

\begin{theorem}[\cite{Apostol:105425}, Teorema 7.11]
  Sea $\alpha$ una función escalonada definida en $[a, b]$ con salto $\alpha_k$ en $x_k$.\\
  
Sea $f$ una función definida en $[a, b]$ tal que $f$ y $\alpha$ no sean ambas discontinuas a la derecha o a la izquierda de cada $x_k$. Entonces $\displaystyle\int_a^b f d \alpha$ existe y se tiene que:
$$
\int_a^b f(x) d \alpha(x)=\sum_{k=1}^n f\left(x_k\right) \alpha_k
$$
\end{theorem}

La prueba de esto se encuentra en \cite{Apostol:105425}, sin embargo, nos será útil explorar la idea.\\

Note que $\alpha$ es constante en los intervalos $(x_{k-1},x_k)$, luego por intervalos la integral es 0 ya que para cualquier suma de Riemann-Stieltjes, $S(P,f,\alpha)$=0. Así, para conocer el valor de la integral entonces solo tendríamos que sumar el valor que toma alrededor de cada $x_k$.\\

Supongamos que $\alpha$ tiene salto $\alpha_k $ en un punto $x_k\in [a,b]$, no es difícil ver que:

\begin{equation}
\int_a^bfd\alpha=f(x_k)[\alpha(x_k+)-\alpha(x_{k}-)]=f(x_k)\alpha_k
\end{equation}

La prueba de esto se encuentra también en \cite{Apostol:105425} [Teorema 7.9], en efecto si repetimos esto para cada $x_k$ obtenemos la suma deseada.\\

Sea $f$ continua en $[0,N]$, el teorema anterior nos permite expresar la suma $\displaystyle\sum_{n=1}^Na_nf(n)$ como una integral de Riemann Stieltjes considerando sus sumas parciales:

$$\displaystyle\sum_{n=1}^Na_nf(n)=\int_0^Nf(x)dA(x)$$

Ya que al aplicar (1.9) tomando como integrador las sumas parciales tenemos que $A(n+)-A(n-)=A(n+1)-A(n)=a_n$, luego en cada paso la integral toma el valor $a_nf(n)$.\\

\begin{note}
El límite inferior de la integral puede ser cualquier número en el intervalo [0, 1) y el superior cualquier número en [N, N+1)
\end{note}

\begin{eg}
\phantom{uwu}
\begin{itemize}
\item Si se toma $\alpha(x)=[x]$, entonces
$$
\int_a^b f(x) d[x]=\sum_{a<n \leq b} f(n)
$$

\item Si se toma $\alpha(x)=\pi(x)$, la función contadora de primos, que tiene un salto de 1 en cada p primo, entonces
$$
\int_a^b f(x) d \pi(x)=\sum_{a<p \leq b} f(p)
$$
\end{itemize}
\end{eg}

\subsection{Algunas propiedades de la integral de Riemann-Stieltjes}


\begin{theorem}[Integración por partes]
    Si $f\in \mathcal{R}(\alpha)$ en $[a,b]$ entonces $\alpha \in\mathcal{R}(f)$ en $[a,b]$ y $$\int_{a}^{b}f(x)d\alpha(x)+\int_{a}^{b}\alpha(x)df(x)=f(b)\alpha(b)-f(a)\alpha(a).$$
\end{theorem}

Bajo ciertas condiciones una integral de Riemann-Stieltjes se puede reducir a una integral de Riemann usual, esto es muy útil puesto que estamos más familiarizados con el cálculo de estas, dichas condiciones son presentadas en el siguiente teorema:

\begin{theorem}\label{reduccion a riemann}
    Sea $ f \in R(\alpha) $ en $[a, b]$, donde $ \alpha \in C^1[a, b]$, entonces,
$ \displaystyle\int_{a}^{b} f(x)\alpha'(x)dx$
existe y\[ \int_{a}^{b} f \,d\alpha = \int_{a}^{b} f(x)\alpha'(x)dx \]
\end{theorem}

Las pruebas de estos teoremas se encuentran también en \cite{Apostol:105425}, por lo que no las presentaremos aquí para no extendernos demasiado en la teoría de esta sección, con estas propiedades ya podemos presentar una prueba  del teorema de  sumación de Abel.

\begin{theorem}\label{Teorema sumacion de Abel}
Sea $a_n$ función aritmética y $f\in C^1[1,x]$, entonces:

$$
\sum_{n \leq x} a_n f(n)=A(x) f(x)-\int_1^x A(t) f^{\prime}(t) d t .
$$
\end{theorem}

\begin{proof}
Tenemos que:

$$\sum_{n \leq x} a_n f(n)=\int_0^xf(t)dA(t)=f(x)A(x)-\int_0^xA(t)df(t)$$

Ya que $A(x)=0$ para todo $x\in [0,1)$, en efecto:

\begin{align*}
    \sum_{n \leq x} a_n f(n)&=f(x)A(x)-\int_1^xA(t)df(t)\\
    &=f(x)A(x)-\int_1^xA(t)f^{'}(t)dt
.\end{align*}

Por  el teorema \ref{reduccion a riemann}.
\end{proof}

\section{Algunas estimaciones básicas}

Vamos a ver algunas aplicaciones de la teoría que hemos presentado, algunas de estas ya las habíamos mencionado antes, por ejemplo, el comportamiento asintótico de las sumas de la serie armónica.\\

Vamos a ver que $\displaystyle\sum_{n \leq x} \frac{1}{n} =\log x+\gamma+O\left(\frac{1}{x}\right)$, donde $\gamma=\displaystyle\lim_{n \to \infty} \left( \sum_{n=1}^{n}\frac{1}{n} -\log n\right)$ conocida como la constante de Euler-Mascheroni\\

Sea $a_n=1$ y $f(x)=\dfrac{1}{x}$, así $A(x)=[x]$ y al usar la sumación parcial tenemos que:


$$
\begin{aligned}
\sum_{n \leq x} \frac{1}{n} & =\frac{[x]}{x}+\int_1^x \frac{[t]}{t^2} d t \\
& =\frac{x-\{x\}}{x}+\int_1^x \frac{t-\{t\}}{t^2} d t
\end{aligned}
$$

Donde $\{x\}$ denota la parte fraccionaria de $x$, es decir $\{x\}=x-[x]$, note que $\{x\}=O(1)$, luego:

\begin{align*}
   \sum_{n \leq x} \frac{1}{n}&=1+O\left(\frac{1}{x}\right)+\log x-\int_1^x \frac{\{t\}}{t^2} d t\\
   &=1+O\left(\frac{1}{x}\right)+\log x-\left(\int_1^{\infty} \frac{\{t\}}{t^2} d t-\int_x^{\infty} \frac{\{t\}}{t^2} d t\right)
.\end{align*}

Basta ver que 1-$\displaystyle\int_1^{\infty}\frac{\{x\}}{x^2}dx=\gamma$ ya que la otra integral también es del orden de $O\left(\dfrac{1}{x}\right)$, en efecto:

$$
\begin{aligned}
r & =\lim _{n \rightarrow \infty}\left(\sum_{k=1}^n \frac{1}{k}-\log n\right) \\
& =\lim _{n \rightarrow \infty}\left(1+\sum_{1<k \leq n} \frac{1}{k}-\log n\right) \\
& =1+\lim _{n \rightarrow \infty}\left(\int_1^n \frac{1}{x} d[x]-\int_1^n \frac{1}{x} d x\right) \\
& =1+\lim _{n \rightarrow \infty}\left(\int_1^n \frac{[x]}{x^2} d x-\int_1^n \frac{1}{x} d x\right)\\
&=1-\int_1^{\infty}\dfrac{\{x\}}{x^2}dx
\end{aligned}
$$

Esto concluye el resultado que mencionamos en la introducción, $H(n)\thicksim \log n$. Veamos otro ejemplo:

\begin{eg}
Estimación de las sumas parciales de $\log n$:

$$
\sum_{n \leq x} \log n=x \log x-x+O(\log x) .
$$

Sea $a_n=1$ y $f(x)=\log x$, así $A(x)=[x]$, luego:
$$
\begin{aligned}
\sum_{n \leq x} \log n & =[x] \log x-\int_1^x \frac{[t]}{t} d t \\
& =(x-O(1)) \log x-\int_1^x \frac{t-O(1)}{t} d t \\
& =x \log x-O(\log x)-(x-1)+O(\log x) \\
& =x \log x-x+O(\log x) .
\end{aligned}
$$
\end{eg}

\subsection{Una equivalencia importante}

Vamos a obtener finalmente que el TNP es equivalente a la afirmación $\psi(x)\thicksim x$

\begin{definition}
Sea $x\in \mathbb{N}$, con $x>1$, definimos la función contadora de primos $\pi(x)$ como: 

    $$\pi(x)=\displaystyle\sum_{p\leq x}1$$
\end{definition}


 Como vimos antes, la fórmula de sumación  de Abel tiene un gran poder teórico que explotaremos en distintos lugares de este trabajo. Por lo pronto ella será esencial para para estimar $\vartheta(x)$ y $\pi(x)$, de donde obtendremos la equivalencia deseada.

\begin{theorem}\label{rep integral de pi x}
Tenemos las siguientes identidades:
    $$
    \begin{aligned}
    & \vartheta(x)=\pi(x) \log x-\int_2^x \frac{\pi(t)}{t} d t, \\
    & \pi(x)=\frac{\vartheta(x)}{\log x}+\int_2^x \frac{\vartheta(t)}{t \log ^2 t} d t .
    \end{aligned}
    $$
\end{theorem}

\begin{proof}
Sea  $\mathbbm{1}_{p}$ la función característica del conjunto de primos. Tenemos entonces las siguientes igualdades:

$$\vartheta(x)=\sum_{n \leqslant x} \mathbbm{1}_p(n) \log (n)\quad \text{y}\quad \pi(x)=\sum_{n \leqslant x} \mathbbm{1}_p(n)$$

Fijemos $x \geqslant 2$. Por la fórmula de sumación de Abel y como $\pi(t)=0$ para todo $t<2$, tenemos que:
$$
\begin{aligned}
\vartheta(x) & =\pi(x) \log (x)-\int_1^x \frac{\pi(t)}{t} d t \\
& =\pi(x) \log (x)-\int_2^x \frac{\pi(t)}{t} d t
\end{aligned}
$$

Notando que $\pi(x)=\displaystyle\sum_{n \leqslant x} \dfrac{\mathbbm{1}_p(n) \log (n)}{\log (n)}$ y que $\vartheta(t)=0$ para todo $t<2$ tenemos que:

$$
\begin{aligned}
\pi(x) & =\frac{\vartheta(x)}{\log (x)}+\int_1^x \frac{\vartheta(t)}{t \log ^2(t)} d t \\
& =\frac{\vartheta(x)}{\log (x)}+\int_2^x \frac{\vartheta(t)}{t \log ^2(t)} d t
\end{aligned}
$$
\end{proof}

Ahora vamos a establecer una conexión entre las dos funciones de Chebyshev que definimos antes, en efecto:

$$
\psi(x)=\sum_{n \leq x} \Lambda(n)=\sum_{m=1}^{\infty} \sum_{p^m \leq x} \Lambda\left(p^m\right)=\sum_{m=1}^{\infty} \sum_{p \leq x^{\frac{1}{m}}} \log p .
$$

Note que la suma sobre $m$ realmente es finita porque la suma sobre $p$, se  detiene cuando $x^{\frac{1}{m}}<2$, es decir, cuando $m>\log_2(x)$, entonces:

\begin{align}
    \psi(x)=\sum_{m \leq \log _2 x} \sum_{p \leq x^{\frac{1}{m}}} \log p=\sum_{m \leq \log _2 x} \vartheta\left(x^{\frac{1}{m}}\right)
\end{align}

\begin{theorem}
    Si $x>0$ se tiene que:
$$
0 \leq \frac{\psi(x)}{x}-\frac{\vartheta(x)}{x} \leq \frac{\log ^2 x}{\sqrt{x} \log 4} .
$$
\end{theorem}


\begin{proof}

Por (1.10) se sigue que:

    $$
\psi(x)=\sum_{2 \leq m \leq \log _2 x} \vartheta\left(x^{\frac{1}{m}}\right)+\vartheta(x) .
$$

Ya que si $m=1$ entonces $\vartheta(x^{\frac{1}{m}})=\vartheta(x)$, luego:

$$
\psi(x)-\vartheta(x)=\sum_{2 \leq m \leq \log _2 x} \vartheta\left(x^{\frac{1}{m}}\right)\geq  0.
$$

Ahora por definición de $\vartheta:$

$$
\vartheta(x)=\sum_{p \leq x} \log p\leq x \log x .
$$

Entonces

\begin{align*}
    0 \leq \psi(x)-\vartheta(x) &\leq \sum_{2 \leq m \leq \log _2 x} x^{\frac{1}{m}} \log x^{\frac{1}{m}} \\
    &\leq \sqrt{x} \sum_{2 \leq m \leq \log _2 x} \log x^{\frac{1}{m}}\\
    &\leq \sqrt{x}(\log_2(x)\log(\sqrt{x}))\\
    &=\frac{\sqrt{x}\log^2 x}{\log(4)}
\end{align*}
\end{proof}

\begin{theorem}
    La afirmación $\psi(x)\thicksim x$ es equivalente a $\vartheta(x)\thicksim x$
\end{theorem}

\begin{proof}
    Por el teorema anterior:

    $$0\leq \dfrac{\psi(x)}{x}-\dfrac{\vartheta(x)}{x}\leq \dfrac{\log^2(x)}{\sqrt{x}\log(4)}$$

    y como $\lim_{x\to \infty} \dfrac{\log^2(x)}{\sqrt{x}\log(4)}=0$, entonces cuando $x\to \infty$ se tiene que $\dfrac{\psi(x)}{x}-\dfrac{\vartheta(x)}{x}=0$, lo que concluye el resultado.
\end{proof}


\begin{theorem}
\label{equivalencia tnp}
    Las siguientes afirmaciones son equivalentes:
    \begin{itemize}
        \item[i)] $\pi(x)\thicksim \dfrac{x}{\log(x)}$

        \item [ii)] $\vartheta(x)\thicksim x$

        \item[iii)] $\psi(x)\thicksim x$
    \end{itemize}    
\end{theorem}

Por el teorema anterior basta ver que $i \leftrightarrow ii$\\

 \begin{proof} Por el teorema \ref{rep integral de pi x} y dado que estamos trabajando con aproximaciones asintóticas, podemos asumir que $x\geq 2$, se sigue que:

 \begin{align}
     \frac{\vartheta(x)}{x}=\frac{\pi(x) \log (x)}{x}-\frac{1}{x} \int_2^x \frac{\pi(t)}{t} d t
 \end{align}
 \begin{align}
     \frac{\pi(x) \log (x)}{x}=\frac{\vartheta(x)}{x}+\frac{\log (x)}{x} \int_2^x \frac{\vartheta(t)}{t \log ^2(t)} d t
 \end{align}

Basta con ver que las integrales de (1.11) y (1.12) van a 0 , cuando $x \rightarrow \infty$.\\

$(\rightarrow)$ Por hipótesis $\dfrac{\pi(x)}{x}\left(\dfrac{1}{\log (x)}\right)^{-1}=1$ cuando $x \rightarrow \infty$. Esto es equivalente a decir que $\dfrac{\pi(t)}{t}=O\left(\dfrac{1}{\log (t)}\right)$. Luego para todo $x \geq 2$ positivo fijo tenemos que:
$$
\frac{1}{x} \int_2^{\mathrm{x}} \frac{\pi(\mathrm{t})}{\mathrm{t}} \mathrm{dt}=O\left(\frac{1}{\mathrm{x}} \int_2^{\mathrm{x}} \frac{1}{\log (\mathrm{t})} \mathrm{dt}\right)
$$

Note que:
$$
\begin{aligned}
\int_2^x \frac{1}{\log (t)} d t & \leq \int_2^{\sqrt{x}} \frac{1}{\log (t)} d t+\int_{\sqrt{x}}^x \frac{1}{\log (t)} d t \\
& \leq \frac{\sqrt{x}}{\log (2)}+\frac{x-\sqrt{x}}{\log (\sqrt{x})}
\end{aligned}
$$

Luego
$$
\frac{1}{x} \int_2^x \frac{1}{\log (t)} d t \leq \frac{1}{\sqrt{x} \log (2)}+\frac{1}{\log (\sqrt{x})}-\frac{1}{\sqrt{x} \log (\sqrt{x})}
$$

Así, cuando $x \rightarrow \infty, \dfrac{1}{x} \displaystyle \int_2^x \frac{1}{\log (t)} d t=0$.\\

$(\leftarrow)$ Análogamente $\vartheta(\mathrm{t})=$ $O(\mathrm{t})$. Por tanto:

$$
\frac{\log (x)}{x} \int_2^x \frac{\vartheta(t)}{t \log ^2(t)} d t=O\left(\frac{\log (x)}{x} \int_2^x \frac{1}{t \log ^2(t)} d t\right)
$$
 
 La integral en $O$ se puede acotar de manera análoga a la anterior:
 
$$
\begin{aligned}
\int_2^x \frac{1}{t \log ^2(t)} d t & =\int_2^{\sqrt{x}} \frac{1}{t \log ^2(t)} d t+\int_{\sqrt{x}}^x \frac{1}{t \log ^2(t)} d t \\
& \leq \frac{\sqrt{x}}{\log ^2(2)}+\frac{x-\sqrt{x}}{\log ^2(\sqrt{x})}
\end{aligned}
$$

Multiplicando ambos lados por $\dfrac{\log (x)}{x}$, podemos ver que si $x \rightarrow \infty$, $\dfrac{\log (x)}{x}\displaystyle \int_2^x \frac{1}{t \log ^2(t)}=0$
\end{proof}

\textcolor{red}{En esta parte faltaría antes de todo introducir todo lo de notación o grande y eso, porque pues se usa  y no lo he ni definido.}